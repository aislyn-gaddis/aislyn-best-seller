{"title":"Cleaning","markdown":{"yaml":{"title":"Cleaning"},"headingText":"Goals of the notebook","containsRefs":false,"markdown":"\n\n\nIn this notebook, I'm going to \n\n- import the Post45 Data Collective's NYT bestseller data set\n- web scrape the NYT Hardcover Fiction List\n- web scrape the NYT Combined Print and E-Book Fiction List\n- clean the data\n- join the two hardcover fiction data sets \n- save the data\n\nI'll load any libraries I might need.\n\n```{r setup}\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(lubridate)\nlibrary(rvest)\n```\n\n## Main Data Import\n\nI'll import the years I already have. I downloaded this from the [Post45 Data Collective](https://data.post45.org/new-york-times-hardcover-fiction-bestsellers-1931-2020-curatorial-statement/) which is run by Emory University. It's every week of the New York Times Bestsellers list going back to when it started in 1931 up to December 2020.\n\n```{r main-import}\nbestsellers <- read_tsv(\"data-raw/nyt_full.tsv\") |> \n  glimpse()\n```\n\n## Hardcover Fiction Web Scrape\n\nNow, I'm going to get the missing years of the hardcover fiction data by web scraping directly from the NYT's website. You might might need to run the code multiple times before it will successfully complete. I also recommend you comment the code after completion since it takes a bit to run.\n\n```{r web-scrape}\nstart_date <- as.Date(\"2020-12-13\")\nend_date <- as.Date(\"2024-11-03\")\n\ndates <- seq(start_date, end_date, by = \"week\")\n\ndfs <- map_dfr(dates, function(date) {\n  url <- sprintf(\"https://www.nytimes.com/books/best-sellers/%s/hardcover-fiction/\", format(date, \"%Y/%m/%d\"))\n  \n  page <- read_html(url)\n  \n  titles <- page %>%\n    html_nodes(\".css-5pe77f\") %>%\n    html_text()\n  \n  authors <- page %>%\n    html_nodes(\".css-hjukut\") %>%\n    html_text()\n  \n  ranks <- seq_along(titles)\n  \n  data.frame(title = titles, author = authors, rank = ranks, date = date)\n})\n\ndfs |> write_rds(\"data-raw/bestsellers-web-scrape.rds\")\n\n```\n\nI'll save the new file into a new object and glimpse it. I also saved the data into a csv just for the purpose of importing it to google sheets later.\n\n```{r bestsellers-two-glimpse}\nbestsellers_two <- read_rds(\"data-raw/bestsellers-web-scrape.rds\") # creating a new object with a file \n\nbestsellers_two |> write_csv(\"data-raw/bestsellers-web-scrape.csv\") # saving the object into a csv to be able to upload it to google sheets\n\nbestsellers_two |> glimpse() # glimpsing the data\n```\n\n## Combined Print and E-book Web Scrape\n\nNow I'll do a similar web scrape to get the combined print and ebook list. This is going through over a decade of data, so you may have to try running it a few times before it successfully completes. I also recommend commenting it after you finish running it. \n\n```{r web-scrape-combined}\nstart_date <- as.Date(\"2011-02-13\")\nend_date <- as.Date(\"2024-11-03\")\n\ndates <- seq(start_date, end_date, by = \"week\")\n\ndfs <- map_dfr(dates, function(date) {\n  url <- sprintf(\"https://www.nytimes.com/books/best-sellers/%s/combined-print-and-e-book-fiction/\", format(date, \"%Y/%m/%d\"))\n  \n  page <- tryCatch(read_html(url), error = function(e) NULL)\n  \n  if (!is.null(page)) {\n    titles <- page %>%\n    html_nodes(\".css-5pe77f\") %>%\n    html_text()\n\n    authors <- page %>%\n    html_nodes(\".css-hjukut\") %>%\n    html_text()\n    \n    ranks <- seq_along(titles)\n    \n    data.frame(title = titles, author = authors, rank = ranks, date = date)\n  } else {\n    NULL\n  }\n})\n\ndfs |> write_rds(\"data-raw/bestsellers-combined-web-scrape.rds\")\n\nbestsellers_combined <- read_rds(\"data-raw/bestsellers-combined-web-scrape.rds\") \n\nbestsellers_combined |> glimpse()\n\n```\n\n## Cleaning\n\nFirst, I'll clean the main data file from the Post45 data collective. The only thing I need to do is remove the title_id column since I won't be using it.\n\n```{r main-clean}\nbestsellers_clean <- bestsellers |> # saving this chunk into a new object and starting with the data\n  select(-title_id) |> # removing the title_id column\n  glimpse() # glimpsing the data\n```\n\nNow, I'll clean the web scrape to make it match the first dataset.\n\n```{r web-scrape-clean}\nbestsellers_two_clean <- bestsellers_two |> # saving this chunk into a new object and starting with the data\n  mutate(year = year(date), # making a year column\n         week = date, # making a new date column called \"week\" to match the first dataset\n         author = str_remove_all(author, \"by \"), # removing the \"by \" from the author column\n         rank = as.numeric(rank)) |> # changing the rank column from int to dbl\n  select(year,\n         week,\n         rank,\n         title,\n         author) |> # putting the columns in the same order as the first dataset\n  glimpse() # glimpsing the data\n```\n\n\nI'll do the same for the combined list. \n\n```{r web-scrape-clean-combined}\nbestsellers_combined_clean <- bestsellers_combined |> # saving this chunk into a new object and starting with the data\n  mutate(year = year(date), # making a year column\n         week = date, # making a new date column called \"week\" to match the first dataset\n         author = str_remove_all(author, \"by \"), # removing the \"by \" from the author column\n         rank = as.numeric(rank)) |> # changing the rank column from int to dbl\n  select(year,\n         week,\n         rank,\n         title,\n         author) |> # putting the columns in the same order as the first dataset\n  glimpse() # glimpsing the data\n```\n\n## Combining the data\n\nNow that both of the hardcover fiction datasets have the same columns, I'll combine them.\n\n```{r combine}\nbestsellers_full <- bestsellers_clean |> # saving this chunk into a new object and starting with the data\n  bind_rows(bestsellers_two_clean) |> # binding the two datasets together\n  glimpse()\n```\n\n## Fixing non-split columns\n\nThere are some columns where the title and author aren't split properly.\n\nI'll start by getting rid of those columns from the main data set, then creating a new object with just those columns to fix them.\n\nThen, I separate the title and author into new columns using the , in between them. I'll also remove the by and the publisher information\n\n```{r column-fix}\nbestsellers_no_na <- bestsellers_full |> # saving the data into a new object\n  filter(!is.na(author)) # removing columns where author is na\n\nbestsellers_na <- bestsellers_full |> # saving the data into a new object\n  filter(is.na(author)) # only including columns where author is na\n\nbestsellers_na_clean <- bestsellers_na |> # saving the data into a new object\n  separate(title, sep = \",\", into = c(\"title\", \"author\")) |> # separate the title column into two columns named title and author based on the comma\n  mutate(author = str_remove_all(author, \"by \")) |> # removing the by\n  mutate(author = str_remove_all(author, \"\\\\(.*\")) |> # removing the publisher information using the ()\n  mutate(author = str_sub(author, end = -3))# removing the period and spaces by removing the last 3 characters of the column\n\nbestsellers_na_clean\n```\n\n## Joining the data again\n\nNow that I've fixed the rows that didn't separate properly, I'll join everything back together.\n\n```{r combine-two}\nbestsellers_full_clean <- bestsellers_no_na |> \n  bind_rows(bestsellers_na_clean) |> \n  glimpse()\n```\nIt looks like everything parsed correctly in the combined list data, so I don't need to worry about that.\n\n## Exporting the data\n\nI'll export the data to my computer as an rds and as a csv\n\n```{r export}\nbestsellers_full_clean |> write_rds(\"data-processed/bestsellers-hardcover.rds\")\nbestsellers_full_clean |> write_csv(\"data-processed/bestsellers-hardcover.csv\")\n\nbestsellers_combined_clean |> write_rds(\"data-processed/bestsellers-combined.rds\")\nbestsellers_combined_clean |> write_csv(\"data-processed/bestsellers-combined.csv\")\n```\n","srcMarkdownNoYaml":"\n\n## Goals of the notebook\n\nIn this notebook, I'm going to \n\n- import the Post45 Data Collective's NYT bestseller data set\n- web scrape the NYT Hardcover Fiction List\n- web scrape the NYT Combined Print and E-Book Fiction List\n- clean the data\n- join the two hardcover fiction data sets \n- save the data\n\nI'll load any libraries I might need.\n\n```{r setup}\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(lubridate)\nlibrary(rvest)\n```\n\n## Main Data Import\n\nI'll import the years I already have. I downloaded this from the [Post45 Data Collective](https://data.post45.org/new-york-times-hardcover-fiction-bestsellers-1931-2020-curatorial-statement/) which is run by Emory University. It's every week of the New York Times Bestsellers list going back to when it started in 1931 up to December 2020.\n\n```{r main-import}\nbestsellers <- read_tsv(\"data-raw/nyt_full.tsv\") |> \n  glimpse()\n```\n\n## Hardcover Fiction Web Scrape\n\nNow, I'm going to get the missing years of the hardcover fiction data by web scraping directly from the NYT's website. You might might need to run the code multiple times before it will successfully complete. I also recommend you comment the code after completion since it takes a bit to run.\n\n```{r web-scrape}\nstart_date <- as.Date(\"2020-12-13\")\nend_date <- as.Date(\"2024-11-03\")\n\ndates <- seq(start_date, end_date, by = \"week\")\n\ndfs <- map_dfr(dates, function(date) {\n  url <- sprintf(\"https://www.nytimes.com/books/best-sellers/%s/hardcover-fiction/\", format(date, \"%Y/%m/%d\"))\n  \n  page <- read_html(url)\n  \n  titles <- page %>%\n    html_nodes(\".css-5pe77f\") %>%\n    html_text()\n  \n  authors <- page %>%\n    html_nodes(\".css-hjukut\") %>%\n    html_text()\n  \n  ranks <- seq_along(titles)\n  \n  data.frame(title = titles, author = authors, rank = ranks, date = date)\n})\n\ndfs |> write_rds(\"data-raw/bestsellers-web-scrape.rds\")\n\n```\n\nI'll save the new file into a new object and glimpse it. I also saved the data into a csv just for the purpose of importing it to google sheets later.\n\n```{r bestsellers-two-glimpse}\nbestsellers_two <- read_rds(\"data-raw/bestsellers-web-scrape.rds\") # creating a new object with a file \n\nbestsellers_two |> write_csv(\"data-raw/bestsellers-web-scrape.csv\") # saving the object into a csv to be able to upload it to google sheets\n\nbestsellers_two |> glimpse() # glimpsing the data\n```\n\n## Combined Print and E-book Web Scrape\n\nNow I'll do a similar web scrape to get the combined print and ebook list. This is going through over a decade of data, so you may have to try running it a few times before it successfully completes. I also recommend commenting it after you finish running it. \n\n```{r web-scrape-combined}\nstart_date <- as.Date(\"2011-02-13\")\nend_date <- as.Date(\"2024-11-03\")\n\ndates <- seq(start_date, end_date, by = \"week\")\n\ndfs <- map_dfr(dates, function(date) {\n  url <- sprintf(\"https://www.nytimes.com/books/best-sellers/%s/combined-print-and-e-book-fiction/\", format(date, \"%Y/%m/%d\"))\n  \n  page <- tryCatch(read_html(url), error = function(e) NULL)\n  \n  if (!is.null(page)) {\n    titles <- page %>%\n    html_nodes(\".css-5pe77f\") %>%\n    html_text()\n\n    authors <- page %>%\n    html_nodes(\".css-hjukut\") %>%\n    html_text()\n    \n    ranks <- seq_along(titles)\n    \n    data.frame(title = titles, author = authors, rank = ranks, date = date)\n  } else {\n    NULL\n  }\n})\n\ndfs |> write_rds(\"data-raw/bestsellers-combined-web-scrape.rds\")\n\nbestsellers_combined <- read_rds(\"data-raw/bestsellers-combined-web-scrape.rds\") \n\nbestsellers_combined |> glimpse()\n\n```\n\n## Cleaning\n\nFirst, I'll clean the main data file from the Post45 data collective. The only thing I need to do is remove the title_id column since I won't be using it.\n\n```{r main-clean}\nbestsellers_clean <- bestsellers |> # saving this chunk into a new object and starting with the data\n  select(-title_id) |> # removing the title_id column\n  glimpse() # glimpsing the data\n```\n\nNow, I'll clean the web scrape to make it match the first dataset.\n\n```{r web-scrape-clean}\nbestsellers_two_clean <- bestsellers_two |> # saving this chunk into a new object and starting with the data\n  mutate(year = year(date), # making a year column\n         week = date, # making a new date column called \"week\" to match the first dataset\n         author = str_remove_all(author, \"by \"), # removing the \"by \" from the author column\n         rank = as.numeric(rank)) |> # changing the rank column from int to dbl\n  select(year,\n         week,\n         rank,\n         title,\n         author) |> # putting the columns in the same order as the first dataset\n  glimpse() # glimpsing the data\n```\n\n\nI'll do the same for the combined list. \n\n```{r web-scrape-clean-combined}\nbestsellers_combined_clean <- bestsellers_combined |> # saving this chunk into a new object and starting with the data\n  mutate(year = year(date), # making a year column\n         week = date, # making a new date column called \"week\" to match the first dataset\n         author = str_remove_all(author, \"by \"), # removing the \"by \" from the author column\n         rank = as.numeric(rank)) |> # changing the rank column from int to dbl\n  select(year,\n         week,\n         rank,\n         title,\n         author) |> # putting the columns in the same order as the first dataset\n  glimpse() # glimpsing the data\n```\n\n## Combining the data\n\nNow that both of the hardcover fiction datasets have the same columns, I'll combine them.\n\n```{r combine}\nbestsellers_full <- bestsellers_clean |> # saving this chunk into a new object and starting with the data\n  bind_rows(bestsellers_two_clean) |> # binding the two datasets together\n  glimpse()\n```\n\n## Fixing non-split columns\n\nThere are some columns where the title and author aren't split properly.\n\nI'll start by getting rid of those columns from the main data set, then creating a new object with just those columns to fix them.\n\nThen, I separate the title and author into new columns using the , in between them. I'll also remove the by and the publisher information\n\n```{r column-fix}\nbestsellers_no_na <- bestsellers_full |> # saving the data into a new object\n  filter(!is.na(author)) # removing columns where author is na\n\nbestsellers_na <- bestsellers_full |> # saving the data into a new object\n  filter(is.na(author)) # only including columns where author is na\n\nbestsellers_na_clean <- bestsellers_na |> # saving the data into a new object\n  separate(title, sep = \",\", into = c(\"title\", \"author\")) |> # separate the title column into two columns named title and author based on the comma\n  mutate(author = str_remove_all(author, \"by \")) |> # removing the by\n  mutate(author = str_remove_all(author, \"\\\\(.*\")) |> # removing the publisher information using the ()\n  mutate(author = str_sub(author, end = -3))# removing the period and spaces by removing the last 3 characters of the column\n\nbestsellers_na_clean\n```\n\n## Joining the data again\n\nNow that I've fixed the rows that didn't separate properly, I'll join everything back together.\n\n```{r combine-two}\nbestsellers_full_clean <- bestsellers_no_na |> \n  bind_rows(bestsellers_na_clean) |> \n  glimpse()\n```\nIt looks like everything parsed correctly in the combined list data, so I don't need to worry about that.\n\n## Exporting the data\n\nI'll export the data to my computer as an rds and as a csv\n\n```{r export}\nbestsellers_full_clean |> write_rds(\"data-processed/bestsellers-hardcover.rds\")\nbestsellers_full_clean |> write_csv(\"data-processed/bestsellers-hardcover.csv\")\n\nbestsellers_combined_clean |> write_rds(\"data-processed/bestsellers-combined.rds\")\nbestsellers_combined_clean |> write_csv(\"data-processed/bestsellers-combined.csv\")\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"01-cleaning.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":"cosmo","title":"Cleaning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}